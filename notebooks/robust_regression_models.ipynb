{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "385fb865",
   "metadata": {},
   "source": [
    "\n",
    "# Robust Regression Models for GPS-Embedded Mobile Map Interaction\n",
    "\n",
    "This notebook fits **robust regression** models (Huber-T loss) for two outcomes:\n",
    "- **Interaction frequency**: `tap_rate_z`\n",
    "- **Interaction regularity**: `cv_iti_z`\n",
    "\n",
    "Predictors include urban form metrics and individual traits:\n",
    "- `orientation_entropy_z`, `closeness_log_z`, `betweenness_log_z`, `degree_mean_z`, `circuity_log_z`\n",
    "- `SA_z` (spatial anxiety), `SBSOD_z` (sense of direction), and `Gender_M`\n",
    "\n",
    "It produces:\n",
    "- Fitted model summaries (text files)\n",
    "- Cross-validated performance (GroupKFold by `partId`) using Median Absolute Deviation (MAD)\n",
    "- Diagnostic plots (histogram of residuals, Q–Q plot, residuals vs fitted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795a06bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.robust.norms import HuberT\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "# Repro settings\n",
    "np.random.seed(42)\n",
    "\n",
    "# Paths\n",
    "DATA_PATH = Path(\"../data/pre-processed_anonimized_final_clean.csv\")\n",
    "OUTPUT_DIR = Path(\"notebooks/outputs\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Python version: {os.sys.version.split()[0]}\\nStatsmodels: {sm.__version__}\")\n",
    "print(f\"Data path: {DATA_PATH.resolve() if DATA_PATH.exists() else DATA_PATH}\")\n",
    "print(f\"Outputs will be saved under: {OUTPUT_DIR.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e4816d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load data\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "df[['SA_z', 'SBSOD_z']] = scaler.fit_transform(df[['SA_Score', 'SBDS_score']])\n",
    "\n",
    "print(\"\\n=== Basic Info ===\")\n",
    "print(df.shape)\n",
    "display(df.head(3))\n",
    "\n",
    "expected_cols = [\n",
    "    'partId','tap_rate_z','cv_iti_z','orientation_entropy_z','closeness_log_z','betweenness_log_z',\n",
    "    'degree_mean_z','circuity_log_z','SA_z','SBSOD_z'\n",
    "]\n",
    "\n",
    "missing = [c for c in expected_cols if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing expected columns: {missing}\")\n",
    "\n",
    "# Gender handling\n",
    "if 'Gender_M' not in df.columns:\n",
    "    if 'Gender' in df.columns:\n",
    "        df['Gender_M'] = (df['Gender'].astype(str).str.upper().str[0] == 'M').astype(float)\n",
    "    else:\n",
    "        # If no Gender label present, default to NaN (will be dropped in complete cases)\n",
    "        df['Gender_M'] = np.nan\n",
    "\n",
    "# Ensure numeric types\n",
    "for col in ['tap_rate_z','cv_iti_z','orientation_entropy_z','closeness_log_z','betweenness_log_z',\n",
    "            'degree_mean_z','circuity_log_z','SA_z','SBSOD_z','Gender_M']:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "print(\"\\n=== Column dtypes (selected) ===\")\n",
    "print(df[['tap_rate_z','cv_iti_z','Gender_M']].dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fab7fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define four model specifications (2 outcomes × 2 network centralities)\n",
    "models_dict = {\n",
    "    \"Tap_Betweenness\": {\n",
    "        \"target\": \"tap_rate_z\",\n",
    "        \"predictors\": [\n",
    "            \"orientation_entropy_z\",\n",
    "            \"betweenness_log_z\",\n",
    "            \"degree_mean_z\",\n",
    "            \"circuity_log_z\",\n",
    "            \"SA_z\",\n",
    "            \"SBSOD_z\",\n",
    "            \"Gender_M\"\n",
    "        ],\n",
    "    },\n",
    "    \"Tap_Closeness\": {\n",
    "        \"target\": \"tap_rate_z\",\n",
    "        \"predictors\": [\n",
    "            \"orientation_entropy_z\",\n",
    "            \"closeness_log_z\",\n",
    "            \"degree_mean_z\",\n",
    "            \"circuity_log_z\",\n",
    "            \"SA_z\",\n",
    "            \"SBSOD_z\",\n",
    "            \"Gender_M\"\n",
    "        ],\n",
    "    },\n",
    "    \"CV_Closeness\": {\n",
    "        \"target\": \"cv_iti_z\",\n",
    "        \"predictors\": [\n",
    "            \"orientation_entropy_z\",\n",
    "            \"closeness_log_z\",\n",
    "            \"degree_mean_z\",\n",
    "            \"circuity_log_z\",\n",
    "            \"SA_z\",\n",
    "            \"SBSOD_z\",\n",
    "            \"Gender_M\"\n",
    "        ],\n",
    "    },\n",
    "    \"CV_Betweenness\": {\n",
    "        \"target\": \"cv_iti_z\",\n",
    "        \"predictors\": [\n",
    "            \"orientation_entropy_z\",\n",
    "            \"betweenness_log_z\",\n",
    "            \"degree_mean_z\",\n",
    "            \"circuity_log_z\",\n",
    "            \"SA_z\",\n",
    "            \"SBSOD_z\",\n",
    "            \"Gender_M\"\n",
    "        ],\n",
    "    },\n",
    "}\n",
    "\n",
    "# Determine intersection of complete cases across all models\n",
    "needed = set(['partId'])\n",
    "for spec in models_dict.values():\n",
    "    needed.update(spec['predictors'])\n",
    "    needed.add(spec['target'])\n",
    "\n",
    "mask = df[list(needed)].notna().all(axis=1)\n",
    "df_clean = df[mask].reset_index(drop=True)\n",
    "print(f\"\\n✅ Final sample size for all models (complete cases): {len(df_clean)} sessions\")\n",
    "\n",
    "groups = df_clean['partId']\n",
    "n_groups = groups.nunique()\n",
    "print(f\"Unique participants (groups): {n_groups}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90520e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fit_rlm(X, y):\n",
    "    Xc = sm.add_constant(X, has_constant='add')\n",
    "    model = sm.RLM(y, Xc, M=HuberT()).fit()\n",
    "    return model\n",
    "\n",
    "def compute_mad(model, y):\n",
    "    return np.median(np.abs(model.fittedvalues - y))\n",
    "\n",
    "def compute_pseudo_r2(model, y):\n",
    "    ss_total = ((y - y.mean()) ** 2).sum()\n",
    "    ss_resid = ((y - model.fittedvalues) ** 2).sum()\n",
    "    return 1 - (ss_resid / ss_total) if ss_total > 0 else np.nan\n",
    "\n",
    "def compute_cv_mad(X, y, groups, n_splits=10):\n",
    "    # Adjust splits to be feasible with the number of groups\n",
    "    n_unique = groups.nunique()\n",
    "    k = min(n_splits, n_unique)\n",
    "    if k < 3:\n",
    "        k = max(2, k)  # ensure at least 2 splits if possible\n",
    "    gkf = GroupKFold(n_splits=k)\n",
    "    mads = []\n",
    "    for train_idx, test_idx in gkf.split(X, y, groups):\n",
    "        X_tr = sm.add_constant(X.iloc[train_idx], has_constant='add')\n",
    "        X_te = sm.add_constant(X.iloc[test_idx], has_constant='add')\n",
    "        model_cv = sm.RLM(y.iloc[train_idx], X_tr, M=HuberT()).fit()\n",
    "        preds = model_cv.predict(X_te)\n",
    "        mads.append(np.median(np.abs(preds - y.iloc[test_idx])))\n",
    "    return float(np.mean(mads)), float(np.std(mads))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95424483",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = []\n",
    "summaries_dir = OUTPUT_DIR / \"summaries\"\n",
    "summaries_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "for name, spec in models_dict.items():\n",
    "    y = df_clean[spec['target']].astype(float)\n",
    "    X = df_clean[spec['predictors']].astype(float)\n",
    "\n",
    "    model = fit_rlm(X, y)\n",
    "\n",
    "    # Save text summary\n",
    "    with open(summaries_dir / f\"{name}_summary.txt\", \"w\") as f:\n",
    "        f.write(model.summary().as_text())\n",
    "\n",
    "    mad = compute_mad(model, y)\n",
    "    r2 = compute_pseudo_r2(model, y)\n",
    "    cv_mean, cv_sd = compute_cv_mad(X, y, groups)\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Target\": spec['target'],\n",
    "        \"Predictors\": \", \".join(spec['predictors']),\n",
    "        \"N\": int(len(y)),\n",
    "        \"MAD\": float(mad),\n",
    "        \"Pseudo_R2\": float(r2),\n",
    "        \"CV_MAD_Mean\": cv_mean,\n",
    "        \"CV_MAD_SD\": cv_sd\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(by=\"Model\").reset_index(drop=True)\n",
    "display(results_df.round(4))\n",
    "\n",
    "# Save performance table\n",
    "results_df.to_csv(OUTPUT_DIR / \"robust_regression_performance.csv\", index=False)\n",
    "print(f\"\\nSaved performance table to: {OUTPUT_DIR / 'robust_regression_performance.csv'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fe0538",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "diag_dir = OUTPUT_DIR / \"diagnostics\"\n",
    "diag_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "def diagnostics_plots(model, y, fitted_name_prefix):\n",
    "    resid = y - model.fittedvalues\n",
    "    standardized_resid = (resid - resid.mean()) / (resid.std(ddof=0) if resid.std(ddof=0) > 0 else 1.0)\n",
    "\n",
    "    # 1) Histogram of residuals\n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.hist(resid, bins=30)\n",
    "    plt.title(\"Histogram of Residuals\")\n",
    "    plt.xlabel(\"Residual\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(diag_dir / f\"{fitted_name_prefix}_hist_residuals.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # 2) Q-Q plot\n",
    "    fig = sm.qqplot(resid, line='45')\n",
    "    plt.title(\"Q–Q Plot of Residuals\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(diag_dir / f\"{fitted_name_prefix}_qqplot.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # 3) Residuals vs Fitted\n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.scatter(model.fittedvalues, standardized_resid, s=18)\n",
    "    plt.axhline(0, linestyle='--', linewidth=1)\n",
    "    plt.axhline(2, linestyle='--', linewidth=1)\n",
    "    plt.axhline(-2, linestyle='--', linewidth=1)\n",
    "    plt.title(\"Standardized Residuals vs Fitted Values\")\n",
    "    plt.xlabel(\"Fitted Values\")\n",
    "    plt.ylabel(\"Standardized Residuals\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(diag_dir / f\"{fitted_name_prefix}_resid_vs_fitted.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Regenerate fitted models for diagnostics\n",
    "for name, spec in models_dict.items():\n",
    "    y = df_clean[spec['target']].astype(float)\n",
    "    X = df_clean[spec['predictors']].astype(float)\n",
    "    model = fit_rlm(X, y)\n",
    "    diagnostics_plots(model, y, fitted_name_prefix=name)\n",
    "\n",
    "print(f\"Diagnostics saved under: {diag_dir}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
